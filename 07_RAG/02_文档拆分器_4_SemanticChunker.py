# @File    : 02_æ–‡æ¡£æ‹†åˆ†å™¨_4_SemanticChunker.py
# @Author  : Kenny So
# @Date    : 2025/11/11 1:09
# @Version : 1.0
import os

import dotenv
from langchain_experimental.text_splitter import SemanticChunker
from langchain_openai import OpenAIEmbeddings

dotenv.load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_BASE"] = os.getenv("OPENAI_BASE_URL")
os.environ["TAVILY_API_KEY"] = os.getenv("TAVILY_API_KEY")

# åˆå§‹åŒ– LLM
embed_model = OpenAIEmbeddings(
    model="text-embedding-3-large"
)

###########################################################
'''
SemanticChunkerï¼šè¯­ä¹‰åˆ†å—
    æ˜¯ LangChain ä¸­ä¸€ç§æ›´é«˜çº§çš„æ–‡æœ¬åˆ†å‰²æ–¹æ³•, å®ƒè¶…è¶Šäº†ä¼ ç»Ÿçš„åŸºäºå­—ç¬¦æˆ–å›ºå®šå¤§å°çš„åˆ†å—æ–¹å¼,
    è€Œæ˜¯æ ¹æ®æ–‡æœ¬çš„è¯­ä¹‰ç»“æ„è¿›è¡Œæ™ºèƒ½åˆ†å—, ä½¿æ¯ä¸ªåˆ†å—ä¿æŒè¯­ä¹‰å®Œæ•´æ€§, ä»è€Œæé«˜æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­‰åº”ç”¨çš„æ•ˆæœã€‚
'''
# 1. åŠ è½½æ–‡æœ¬
with open("asset/09-ai1.txt", encoding="utf-8") as f:
    state_of_the_union = f.read()  # è¿”å›å­—ç¬¦ä¸²

# 2. è·å–åˆ‡å‰²å™¨
text_splitter = SemanticChunker(
    embeddings=embed_model,
    breakpoint_threshold_type="percentile",  # æ–­ç‚¹é˜ˆå€¼ç±»å‹ï¼šå­—é¢å€¼["ç™¾åˆ†ä½æ•°", "æ ‡å‡†å·®", "å››åˆ†ä½è·", "æ¢¯åº¦"] é€‰å…¶ä¸€
    breakpoint_threshold_amount=50.0  # æ–­ç‚¹é˜ˆå€¼æ•°é‡ (æä½é˜ˆå€¼ â†’ é«˜åˆ†å‰²æ•æ„Ÿåº¦)
)

# 3.åˆ‡åˆ†æ–‡æ¡£
docs = text_splitter.create_documents(texts=[state_of_the_union])

# 4. æ‰“å°
print(len(docs))
for doc in docs:
    print(f"ğŸ” æ–‡æ¡£ {doc}:")
